{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1-HdRR266M6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Conv2d(in_channels=4,  # 입력데이터의 channel 수\n",
    "                  out_channels=2, # filter(kernel) 수\n",
    "                  kernel_size=3,  # filter 크기(3:h, 3:w)\n",
    "                  # stride=1,  # 이동크기 => 좌우, 상하 1칸씩 이동하면서 계산\n",
    "                  # padding=0  # 패딩크기\n",
    "                  # pading='same'\n",
    "                 )\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2992]],\n",
       "\n",
       "         [[-0.8028]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.ones(1, 4, 3, 3)  # (데이터개수, channel, height, width)\n",
    "feature_map = layer(input_data)\n",
    "print(feature_map.shape)\n",
    "# [1:데이터개수, 2:out_channels, 1:height, 1:width]\n",
    "feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 weight\n",
    "weight = layer.weight  # conv2d의 weight 조회 => filter 조회\n",
    "weight.shape\n",
    "# [2:필터개수, 4:필터채널개수, 3:필터height, 3:필터width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0547, 0.0255], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 bias\n",
    "bias = layer.bias\n",
    "bias.shape  # [2:필터개수]\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 3, 3]), torch.Size([4, 3, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 필터 계산\n",
    "input_data.shape, weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4290, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1 = torch.sum(input_data[0, 0] * weight[0, 0])  # [0: 첫번째 필터, 0: 첫번째 채널]\n",
    "ch2 = torch.sum(input_data[0, 1] * weight[0, 1])  # [0: 첫번째 필터, 1: 두번째 채널]\n",
    "ch3 = torch.sum(input_data[0, 2] * weight[0, 2])  # [0: 첫번째 필터, 2: 세번째 채널]\n",
    "ch4 = torch.sum(input_data[0, 3] * weight[0, 3])  # [0: 첫번째 필터, 3: 네번째 채널]\n",
    "result = ch1 + ch2 + ch3 + ch4 + bias[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2111, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1 = torch.sum(input_data[0, 0] * weight[1, 0])  # [0: 첫번째 필터, 0: 첫번째 채널]\n",
    "ch2 = torch.sum(input_data[0, 1] * weight[1, 1])  # [0: 첫번째 필터, 1: 두번째 채널]\n",
    "ch3 = torch.sum(input_data[0, 2] * weight[1, 2])  # [0: 첫번째 필터, 2: 세번째 채널]\n",
    "ch4 = torch.sum(input_data[0, 3] * weight[1, 3])  # [0: 첫번째 필터, 3: 네번째 채널]\n",
    "result = ch1 + ch2 + ch3 + ch4 + bias[1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5867, 0.7289, 0.4778, 0.0056],\n",
       "         [0.1397, 0.0298, 0.4811, 0.2341],\n",
       "         [0.5840, 0.4845, 0.5535, 0.7211],\n",
       "         [0.3153, 0.3078, 0.4132, 0.3489]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_layer= nn.MaxPool2d(kernel_size=2,  # 최대값을 추출할 영역 크기\n",
    "                      stride=2        # 이동 size => kernel_size와 stride는 같은 값을 지정해서 영역이 겹치지 않도록 함\n",
    "                     )\n",
    "# kernel_size보다 작은 영역에서는 최대값을 추출 X => padding을 지정해서 zero_padding을 추가해서 작은 영역에서도 추출가능하게 함\n",
    "input_data2 = torch.rand(1, 4, 4)\n",
    "input_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = p_layer(input_data2)\n",
    "result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7289, 0.4811],\n",
       "         [0.5840, 0.7211]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/Users/hongdagyeong/Documents/Pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from module.data import load_mnist_dataset, load_fashion_mnist_dataset\n",
    "from module.train import fit\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "N_EPOCH=1\n",
    "BATCH_SIZE=256\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_loader = load_mnist_dataset('08_datasets', BATCH_SIZE, True)  # 저장경로, batch크기, Trainset여부\n",
    "test_loader = load_mnist_dataset('08_datasets', BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fashion MNISt\n",
    "train_loader = load_fashion_mnist_dataset('08_datasets', BATCH_SIZE, True)  # 저장경로, batch크기, Trainset여부\n",
    "test_loader = load_fashion_mnist_dataset('08_datasets', BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: 08_datasets\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: 08_datasets\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN -> Convolution Layer: filter 개수(out_channels로 설정) 뒤로 갈수록 크게 잡는다\n",
    "#        Maxpooling layer를 이용해서 출력 결과(Feature map)의 size(height, width)는 줄여나간다 (보통 절반씩 줄인다)\n",
    "\n",
    "# conv block\n",
    "## 1. Conv + ReLU + MaxPooling\n",
    "## 2. Conv + BatchNorm + ReLU + MaxPooling\n",
    "## 3. Conv + BatchNorm + ReLU + Dropout + MaxPooling\n",
    "\n",
    "class MNISTCNNMODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = nn.Sequential(\n",
    "            # Conv2d(): 3 x 3 필터, stride=1, padding=1 => same padding (입력 size와 출력 size가 동일)\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),  # channel을 기준으로 정규화 -> 입력 channel수 지정\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            # kernel_size와 stride가 같을 경우에는 stride 생략\n",
    "            # MaxPool2d() 에서도 padding 지정\n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.MaxPool2d(kernel_size=2, padding=1)  # 입려력: 7 x 7 => 1/2 줄이면 -> 3.5 -> 0.5를 살리기 위해 padding 지정\n",
    "        )\n",
    "        \n",
    "        # 결과출력 LAYER => linear() 사용\n",
    "        self.output_block = nn.Sequential(\n",
    "            # MaxPool2d() 출력결과 입력으로 받음 => 4차원 (batch, ch, h, w)\n",
    "            # 3차원 -> 1차원\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128*4*4, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 10)  # out => 클래스 개수\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.b1(X)\n",
    "        out = self.b2(out)\n",
    "        out = self.b3(out)\n",
    "        out = self.output_block(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MNISTCNNMODEL                            [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 28, 28]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 28, 28]           --\n",
       "│    └─Dropout2d: 2-4                    [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 32, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 64, 7, 7]             --\n",
       "│    └─Conv2d: 2-6                       [1, 64, 14, 14]           18,496\n",
       "│    └─BatchNorm2d: 2-7                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-8                         [1, 64, 14, 14]           --\n",
       "│    └─Dropout2d: 2-9                    [1, 64, 14, 14]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-3                        [1, 128, 4, 4]            --\n",
       "│    └─Conv2d: 2-11                      [1, 128, 7, 7]            73,856\n",
       "│    └─BatchNorm2d: 2-12                 [1, 128, 7, 7]            256\n",
       "│    └─ReLU: 2-13                        [1, 128, 7, 7]            --\n",
       "│    └─Dropout2d: 2-14                   [1, 128, 7, 7]            --\n",
       "│    └─MaxPool2d: 2-15                   [1, 128, 4, 4]            --\n",
       "├─Sequential: 1-4                        [1, 10]                   --\n",
       "│    └─Flatten: 2-16                     [1, 2048]                 --\n",
       "│    └─Linear: 2-17                      [1, 512]                  1,049,088\n",
       "│    └─ReLU: 2-18                        [1, 512]                  --\n",
       "│    └─Dropout: 2-19                     [1, 512]                  --\n",
       "│    └─Linear: 2-20                      [1, 10]                   5,130\n",
       "==========================================================================================\n",
       "Total params: 1,147,338\n",
       "Trainable params: 1,147,338\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.55\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.71\n",
       "Params size (MB): 4.59\n",
       "Estimated Total Size (MB): 5.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MNISTCNNMODEL()\n",
    "summary(model, (1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1] - Train loss: 0.33341 Train Accucracy: 0.87657 || Validation Loss: 0.35633 Validation Accuracy: 0.86810\n",
      "====================================================================================================\n",
      "116.07930612564087 초\n"
     ]
    }
   ],
   "source": [
    "# Fashion MNIST\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "device = 'cpu'\n",
    "\n",
    "result = fit(train_loader, test_loader, model, loss_fn, optimizer, N_EPOCH,\n",
    "             save_best_model=False, early_stopping=True, device=device, mode='multi')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2ARCyjDW66NR",
    "6bAN1wPG66NS",
    "shNUg6al66NV",
    "7xgQxAU666NZ"
   ],
   "name": "07_CNN_MNIST분류, 모델저장.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
